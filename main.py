import PyPDF2
import streamlit as st
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate


def extract_text_from_pdf(pdf_file):
    """
    Extracts text from a PDF file.

    Args:
        pdf_file (UploadedFile): A Streamlit `UploadedFile` object representing the PDF file.

    Returns:
        str: Extracted text from the PDF file, or None if an error occurs.
    """
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        extracted_text = ''.join(page.extract_text() for page in pdf_reader.pages)
        return extracted_text
    except Exception as e:
        st.error(f"Failed to extract text from PDF: {e}")
        return None


def get_response(text, user_query, chat_history, API_KEY=None):
    """
    Generates a response from an AI model based on the provided text, user query, and chat history.

    Args:
        text (str): The extracted text from the medical report.
        user_query (str): The user's query about the medical report.
        chat_history (list): A list of tuples representing the chat history, where each tuple is (role, message).

    Returns:
        str: The response generated by the AI model, or an error message if response generation fails.
    """
    llm = ChatGroq(
        # model="llama-3.2-3b-preview",
        model="llama3-70b-8192",
        temperature=0,
        max_tokens=None,
        timeout=None,
        max_retries=2,
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            ('system',
             'You are a helpful assistant. Analyze the following medical test report and respond to user queries.'),
            ('user', f"Medical Test Report:\n{text}")
        ] + chat_history + [('user', user_query)]
    )

    output = StrOutputParser()
    chain = prompt | llm | output

    try:
        response = chain.invoke({})
        return response
    except Exception as e:
        st.error(f"Failed to generate response: {e}")
        return "Sorry, I couldn't process your query at the moment."


def main():
    """
    The main function for running the Streamlit app.
    Handles file upload, text extraction from PDFs, and interaction with an AI assistant.

    Features:
    - Allows users to upload a PDF medical report.
    - Extracts text from the uploaded PDF.
    - Provides a chat interface for querying an AI assistant about the report.
    """
    load_dotenv()

    st.set_page_config(page_title='Medical Test Explanation.', page_icon='ðŸ©º', layout="wide")
    st.title('Medical Test Explanation ðŸ©º')

    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []

    st.sidebar.header("Upload Section")
    st.subheader("Chat with the Assistant:")

    upload_pdf = st.sidebar.file_uploader('Upload Medical Test: ', type=['pdf'])

    # Sidebar for Groq API key and link
    st.sidebar.title("Settings")
    api_key = st.sidebar.text_input("Enter your API Key:", type="password")

    st.sidebar.subheader("Steps to Get API Key:")
    st.sidebar.markdown(
        "1. Sign In Groq-Cloud: [Groq-Cloud](https://console.groq.com/keys)")
    st.sidebar.markdown(
        "2. Create API-KEY: [Groq-API](https://console.groq.com/keys)")
    st.sidebar.markdown("3. Copy the API and paste in input area.")

    if upload_pdf:
        if 'text_pdf' not in st.session_state:
            with st.spinner("Extracting text from PDF..."):
                st.session_state.text_pdf = extract_text_from_pdf(upload_pdf)
                st.sidebar.success("PDF text extracted successfully!")

                if api_key:
                    response = get_response(text=st.session_state.text_pdf,
                                            user_query='Tell me about this medical test',
                                            chat_history=st.session_state.chat_history, API_KEY=api_key)
                else:
                    response = get_response(text=st.session_state.text_pdf,
                                            user_query='Tell me about this medical test',
                                            chat_history=st.session_state.chat_history)

                st.session_state.chat_history.append(('assistant', response))

    if upload_pdf and st.session_state.text_pdf:
        for message in st.session_state.chat_history:
            role, content = message
            with st.chat_message(role):
                st.write(content)


        user_query = st.chat_input('Enter Your Question: ')
        if user_query:
            st.session_state.chat_history.append(('user', user_query))
            with st.spinner("Generating response..."):

                if api_key:
                    response = get_response(text=st.session_state.text_pdf,
                                            user_query=user_query,
                                            chat_history=st.session_state.chat_history, API_KEY=api_key)
                else:
                    response = get_response(text=st.session_state.text_pdf,
                                            user_query=user_query,
                                            chat_history=st.session_state.chat_history)

                st.session_state.chat_history.append(('assistant', response))

            with st.chat_message('user'):
                st.write(user_query)

            with st.chat_message('assistant'):
                st.write(response)


if __name__ == '__main__':
    main()